{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ramnet\n",
    "using ramnet.Models: predict_response, BleachingDiscriminator\n",
    "using ramnet.Utils: stack, accuracy, ambiguity\n",
    "using Images\n",
    "using MLDatasets\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Weightless Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. An initial example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first example of how we can employ weightless models, let's tackle the task of distinguishing two characters in 3x3 pixel images: the 'T' and 'H' characters.Below we can see the two images we will be using as training examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJoAAABCAQAAAACH6fL4AAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QAAd2KE6QAAAAzSURBVDjLY2CAAvv//xkYmP///8CABEYFh5jg//9/GBj4/4MAQsWo4HAQxBrFo4JDRhAAQB0Tea+tYUUAAAAASUVORK5CYII=",
      "text/plain": [
       "3×7 MosaicView{Gray{Bool},4,Base.ReshapedArray{Gray{Bool},4,PaddedView{Gray{Bool},3,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},Array{Gray{Bool},3}},Tuple{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64}}}}:\n",
       " Gray{Bool}(false)  Gray{Bool}(false)  …  Gray{Bool}(false)\n",
       " Gray{Bool}(true)   Gray{Bool}(false)     Gray{Bool}(false)\n",
       " Gray{Bool}(true)   Gray{Bool}(false)     Gray{Bool}(false)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = Bool[0 0 0; 1 0 1; 1 0 1]\n",
    "H = Bool[0 1 0; 0 0 0; 0 1 0]\n",
    "\n",
    "mosaicview(Gray.(T), Gray.(H); nrow=1, npad=1, fillvalue=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train a model using these images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = stack(vec(T), vec(H)), [\"T\", \"H\"]\n",
    "\n",
    "model = MultiDiscriminatorClassifier{String}(3; seed=1)\n",
    "\n",
    "train!(model, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test and see that the trained model is able to correctly classify the training images: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{String,1}:\n",
       " \"T\"\n",
       " \"H\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Array{Int64,1}} with 2 entries:\n",
       "  \"T\" => [3, 0]\n",
       "  \"H\" => [0, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_response(model, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to classify images already seen during training, however, is not very impressive. What is truly of interest to us is seeing how this model fares agains never before seen images. Let's prepare some novel data and test it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMYAAAA2AQAAAAC0ctvpAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QAAd2KE6QAAAAzSURBVDjLY2AAAv7/QMDAYP//AwMziHkAKPKHYVRmqMpAaLAMCEBlQGBUZlRmVGaQyAAA2RSJY/HGWCEAAAAASUVORK5CYII=",
      "text/plain": [
       "3×11 MosaicView{Gray{Bool},4,Base.ReshapedArray{Gray{Bool},4,PaddedView{Gray{Bool},3,Tuple{Base.OneTo{Int64},Base.OneTo{Int64},Base.OneTo{Int64}},Array{Gray{Bool},3}},Tuple{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64},Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64}}}}:\n",
       " Gray{Bool}(false)  Gray{Bool}(false)  Gray{Bool}(true)  …  Gray{Bool}(true)\n",
       " Gray{Bool}(true)   Gray{Bool}(false)  Gray{Bool}(true)     Gray{Bool}(false)\n",
       " Gray{Bool}(true)   Gray{Bool}(false)  Gray{Bool}(true)     Gray{Bool}(false)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kinda_T = Bool[0 0 1; 1 0 1; 1 0 1]\n",
    "kinda_H = Bool[0 1 0; 0 0 0; 0 0 0]\n",
    "kinda_nothing = Bool[1 0 1; 1 0 0; 1 0 0]\n",
    "\n",
    "mosaicview(Gray.(kinda_T), Gray.(kinda_H), Gray.(kinda_nothing); nrow=1, npad=1, fillvalue=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{String,1}:\n",
       " \"T\"\n",
       " \"H\"\n",
       " \"T\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = stack(map(vec, [kinda_T, kinda_H, kinda_nothing])...)\n",
    "\n",
    "predict(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String,Array{Int64,1}} with 2 entries:\n",
       "  \"T\" => [2, 0, 1]\n",
       "  \"H\" => [0, 2, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_response(model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The responses show us that even tough they don't perfectly fit the model's concept of the characters, it reasonably classifies the first two images as a 'T' and an 'H', respectively. The last one may not look like any particular character for most of us, but ends up being classified as a 'T', altough its response is small and could be interpreted as a classification with low confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Going beyond toy examples: classification of handwritten digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the results shown above may not seen that impressive. Truly, they are not. distinguishing between images made of 9 measly pixels is not a hard task at all. However, weightless neural networks are in no way limited to such low dimension problems. Since its inception, these models have been employed at considerably harder tasks. One higher-dimensional example (that still does not represent an upper limit of the paradigm) is the classification of handwritten digits from the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = permutedims(reshape(MNIST.traintensor(), 784, :)) .> 0.5\n",
    "y_train = MNIST.trainlabels()\n",
    "\n",
    "X_test = permutedims(reshape(MNIST.testtensor(), 784, :)) .> 0.5\n",
    "y_test = MNIST.testlabels()\n",
    "\n",
    "model_digits = MultiDiscriminatorClassifier(28; seed=2)\n",
    "\n",
    "time_train!(model, X, y) = @btime train!($model, $X, $y)\n",
    "\n",
    "# time_train!(model_digits, X_train, y_train)\n",
    "train!(model_digits, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_accuracy(y_pred, y_target) = @btime accuracy($y_pred, $y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.040 μs (3 allocations: 5.55 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8357"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_accuracy(predict(model_digits, X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is similar to what I get with `wisardpkg` with bleaching **deactivated** but worst then the accuracy when it's activated. Bleaching could be understood as a disambiguation technique, for when there is a tie between discriminators' responses during classification. Before making use of bleaching, it would be interesting to measure the frequency of draws in the classfication of this test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1479"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambiguity(values(predict_response(model_digits, X_test))...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More then **14%** of the test images are tying and we should assume that a good number of them are being misclassified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models used so far have at their core RAM neurons that address single-bit words. If instead we make use of neurons that address multi-bit words, we could associate to every possible input pattern to that neuron not only its occurance in the dataset but also its frequency. These frequencies give us an extra dimension in comparing discriminators and may be used as a disambiguation mechanism. One way in which the frequencies are used is by defining a bleaching threshold **b** for the neuron. In such a scheme an input pattern activates the neuron only with its observed frequency during training was greater than **b**. Notice that we can achieve the same activation behavior  of the previously seen neurons by setting **b** to zero.\n",
    "\n",
    "`BleachingDiscriminator` is one that makes use of `AccNode` neurons, where each address is associated with a counter. Classifiers that make use of this discriminator may specify a bleaching threshold as explained above during prediction. For example, training such a bleaching-enabled classifier with the MNIST dataset and using a bleaching threshold of 4, we can attain a considerable gain in accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bleaching = MultiDiscriminatorClassifier{Int64,BleachingDiscriminator}(28; seed=2)\n",
    "\n",
    "train!(model_bleaching, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.035 μs (3 allocations: 5.55 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9145"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_accuracy(predict(model_bleaching, X_test; b=4), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see that the ambiguity went down:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0453"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ambiguity(values(predict_response(model_bleaching, X_test; b=4))...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have done just now was manually setting a bleaching threshold that was used for all test patterns. However, different patterns may require different levels of bleaching. Additionally, is it really necessary for us to select it manually? Truly, we can achieve a better classification performance if we select thresholds on a case by case basis and we can employ a simple and automatic selection strategy instead of doing it by hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.053 μs (3 allocations: 5.55 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.921"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_accuracy(predict(model_bleaching, X_test; b=:linear), y_test)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
